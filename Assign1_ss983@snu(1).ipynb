{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('statlog+shuttle/shuttle.trn', header=None)\n",
    "data_test = pd.read_csv('statlog+shuttle/shuttle.tst', header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the data was of type object, we convert it into integers first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = data_test[0].str.split(' ', expand=True).astype(int)\n",
    "new_train = data_train[0].str.split(' ', expand=True).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data looks like this-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = new_train[9].value_counts()\n",
    "print(f_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test = new_test[9].value_counts()\n",
    "print(f_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dataset is very skewed towards class 1, even if we mix up the dataset and randomize it, it probably would not make much of a difference- hence we will do the X and y split here itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = new_train.iloc[:, :-1].values\n",
    "X_test = new_test.iloc[:, :-1].values\n",
    "y_train = new_train.iloc[:, -1].values\n",
    "y_test = new_test.iloc[:, -1].values\n",
    "\n",
    "bdr_y_train = y_train\n",
    "bdr_y_test = y_test\n",
    "bdr_X_train = X_train\n",
    "bdr_X_test = X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can try our classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most of our classes are 1's, we can remove some of them from the training data to see if it improves performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1s = []\n",
    "for i, _ in enumerate(X_train):\n",
    "    if (y_train[i] == 1):\n",
    "        X_1s.append(X_train[i])\n",
    "print(len(X_1s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rest = []\n",
    "y_rest = []\n",
    "for i, _ in enumerate(X_train):\n",
    "    if (y_train[i] != 1):\n",
    "        X_rest.append(X_train[i])\n",
    "        y_rest.append(y_train[i])\n",
    "print(len(X_rest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the X's having class as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = len(X_1s)/6748\n",
    "times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 1's are 5x more than the next best class, we remove half of the X's from the TRAINING SET only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_1s = [1]*34108\n",
    "X_train_1s, X_test_1s, y_train_1s, y_test_1s = train_test_split(\n",
    "    X_1s, y_1s, test_size=0.5)\n",
    "print(len(X_train_1s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1s  # Randomly selected 50% of X_1s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1s = pd.DataFrame(X_train_1s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rest = pd.DataFrame(X_rest)\n",
    "y_rest = pd.DataFrame(y_rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rest.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1s = [1]*len(X_train_1s)\n",
    "y_1s = pd.DataFrame(y_1s)\n",
    "y_1s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, we have Xs which is not too skewed towards 1, and all of the other elements in the dataset remains.\n",
    "WE can merge it now to create our grand X_train dataset finally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_1s, X_rest], axis=0, ignore_index=True)\n",
    "y_train = pd.concat([y_1s, y_rest], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = lda.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got accuracy of 96.9 ~ 97% by doing the right preprocessing of our data for LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we try the same analysis on QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "correlation_matrix = X_train.corr()\n",
    "\n",
    "# Display the correlation matrix as a heatmap\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_dim_red = LDA(n_components=4)\n",
    "X_train = lda.fit_transform(X_train, y_train)\n",
    "X_test = lda.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_qda = qda.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred_qda, y_test)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The Notebook sometimes before running shows a weird output that shows the accuracy to be 0.00ish something, but once you run it, it resolves, I am not exactly sure why that error happens, but if you run the code it shows the accuracy correctly ~ 95%ish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally we attempt to create a BDR classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdr_y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = [0]*7\n",
    "for i in bdr_y_train:\n",
    "    prior_probs[i-1] += 1\n",
    "prior_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate(prior_probs):\n",
    "    prior_probs[i]/=len(bdr_y_train)\n",
    "prior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to normalize the data for bdr sets also\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc2 = StandardScaler()\n",
    "bdr_X_train = sc.fit_transform(bdr_X_train)\n",
    "bdr_X_test = sc.transform(bdr_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "grid_size = 0.2\n",
    "\n",
    "# Create a list of class labels\n",
    "class_labels = np.unique(bdr_y_train)\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "kde_models = {}\n",
    "for label in class_labels:\n",
    "    class_samples = bdr_X_train[bdr_y_train == label]\n",
    "\n",
    "    # Create and fit a KDE model for the class\n",
    "    kde = KernelDensity(bandwidth=0.5)  # Adjust bandwidth as needed\n",
    "    kde.fit(class_samples)\n",
    "\n",
    "    # Store the KDE model for this class\n",
    "    kde_models[label] = kde\n",
    "\n",
    "# Convert bdr_X_test back to a Pandas DataFrame\n",
    "bdr_X_test = pd.DataFrame(bdr_X_test)\n",
    "\n",
    "# Iterate through each test sample\n",
    "for i in range(len(X_test)):\n",
    "    # Calculate the grid element where the test sample is located\n",
    "    grid_element = np.floor(bdr_X_test.iloc[i] / grid_size)\n",
    "\n",
    "    # Calculate the class with the highest prior probability in the grid element\n",
    "    max_posterior_prob = -1\n",
    "    predicted_label = None\n",
    "\n",
    "    for label in class_labels:\n",
    "        # Calculate prior probability for the class\n",
    "        prior_prob = np.sum(\n",
    "            bdr_y_train[bdr_y_train == label]) / len(bdr_y_train)\n",
    "\n",
    "        # Calculate the density using the KDE model for the class\n",
    "        log_density = kde_models[label].score_samples([bdr_X_test.iloc[i]])\n",
    "\n",
    "        # Calculate the posterior probability\n",
    "        posterior_prob = prior_prob * np.exp(log_density)\n",
    "\n",
    "        # Check if this class has a higher posterior probability\n",
    "        if (posterior_prob > max_posterior_prob):\n",
    "            max_posterior_prob = posterior_prob\n",
    "            predicted_label = label\n",
    "\n",
    "    y_pred.append(predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"BDR Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To think about: What is the complexity of building the BDR classifier? What will happen if the\n",
    "number of attributes and the number of feature vectors in the learning set are large?\n",
    "\n",
    "Training the BDR classifier takes a very long time, even on this small dataset, if the Learning Set is huge, BDR is not feasible for real time applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
